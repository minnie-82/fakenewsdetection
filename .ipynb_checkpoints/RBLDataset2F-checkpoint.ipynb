{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oqTWJZNjctKq"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dEB2aSgTgy7M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJU52JGEeEBs"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('/content/drive/MyDrive/ARBLDataset/Fake_Real.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "20iiJecNhs-i",
    "outputId": "3c2e46d8-c15d-4b21-f659-716b6d579fa2"
   },
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yylhH2Qhhvwt",
    "outputId": "277d86d0-2625-4b1c-e458-ec65cb3db74f"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FEnsd_Zwhv7o",
    "outputId": "f58127fa-f6cd-42e8-ec71-92e3bdc70e5a"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGkq8N99hwHk"
   },
   "outputs": [],
   "source": [
    "df['text'].fillna('', inplace=True)\n",
    "df['subject'].fillna('Unknown', inplace=True)\n",
    "df['target'].fillna(df['target'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tddZwIe4hmtW",
    "outputId": "9baaa69a-e4bf-4015-8e58-745d308e5b03"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mx3LyohxeTYD",
    "outputId": "bd2778a8-c5bb-493d-9fb2-89bbf2b04c24"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Function to clean text\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = str(text)  # Ensure text is a string\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'<.*?>', '', text)    # Remove HTML tags\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove punctuation, keep only letters and spaces\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "# Apply text cleaning\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Function for tokenization\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# Apply tokenization\n",
    "df['tokens'] = df['cleaned_text'].apply(tokenize_text)\n",
    "\n",
    "# Set up stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to remove stop words\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "# Apply stop word removal\n",
    "df['tokens'] = df['tokens'].apply(remove_stopwords)\n",
    "\n",
    "# Set up lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function for lemmatization\n",
    "def lemmatize_tokens(tokens):\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "# Apply lemmatization\n",
    "df['tokens'] = df['tokens'].apply(lemmatize_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Ht28yCqleQaM",
    "outputId": "76414cf8-d5c5-4192-aab3-00231ac4011e"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FuY6cB-Rekov",
    "outputId": "64ba730a-d04d-4374-d5e2-289530e7d5be"
   },
   "outputs": [],
   "source": [
    "# Display the preprocessed DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "id": "2A1iY4HTerWD",
    "outputId": "50852123-7ced-47a4-f091-b10004ca8d85"
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")  # Optional: Set the style of the plot\n",
    "colors = [\"red\", \"blue\"]\n",
    "sns.countplot(x=\"target\", data=df, palette=colors)\n",
    "plt.title('Number of Fake and Real News')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrbmVxJ-eubD",
    "outputId": "20692533-c5e3-46eb-b99f-6d38eed42401"
   },
   "outputs": [],
   "source": [
    "labels=df.target\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "id": "ujA4i1Fe61M9",
    "outputId": "e6328eb3-0012-4576-ddfa-0467511d2d3d"
   },
   "outputs": [],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "id": "_w5m_x9w69mE",
    "outputId": "c1fe37c3-2eac-42bb-bd5c-c663e1ac64d9"
   },
   "outputs": [],
   "source": [
    "df['cleaned_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "id": "AZQB3MRQHeP2",
    "outputId": "ec75165d-044f-424e-a0d5-c80d2957246c"
   },
   "outputs": [],
   "source": [
    "df['cleaned_text'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CEEFCm4me1EZ",
    "outputId": "9279219e-2077-4e77-a1bb-4bdf313343bd"
   },
   "outputs": [],
   "source": [
    "target=df.target.value_counts()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXoG5NJigDP-"
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(df['cleaned_text'], labels, test_size=0.2, random_state=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Ki1YkFsgo3p"
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "#Fit and transform train set, transform test set\n",
    "tfidf_train=tfidf_vectorizer.fit_transform(x_train)\n",
    "tfidf_test=tfidf_vectorizer.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ox01ZMrLlkaw",
    "outputId": "2db46977-391a-4a4c-a043-13c850d998c5"
   },
   "outputs": [],
   "source": [
    "#Initialize a PassiveAggressiveClassifier\n",
    "pac=PassiveAggressiveClassifier(max_iter=50)\n",
    "pac.fit(tfidf_train,y_train)\n",
    "#Predict on the test set and calculate accuracy\n",
    "y_pred=pac.predict(tfidf_test)\n",
    "score=accuracy_score(y_test,y_pred)\n",
    "print(f'Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j33Gl1aFJYzB",
    "outputId": "dc19917d-4e9d-41b5-a2fb-1ed34b128c6e"
   },
   "outputs": [],
   "source": [
    "# Calculate Precision\n",
    "precision = precision_score(y_test, y_pred, pos_label='True')\n",
    "print(f'Precision: {round(precision*100, 2)}%')\n",
    "\n",
    "# Calculate Recall\n",
    "recall = recall_score(y_test, y_pred, pos_label='True')\n",
    "print(f'Recall: {round(recall*100, 2)}%')\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1 = f1_score(y_test, y_pred, pos_label='True')\n",
    "print(f'F1 Score: {round(f1*100, 2)}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "xT5WQXjSlmLa",
    "outputId": "d47b6761-f12b-4256-c13b-8ca1560881a3"
   },
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "labels = ['Fake', 'True']\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "# Create a heatmap to visualize the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3X_L164lpHb",
    "outputId": "b1049cab-a3b6-4d09-ad5c-9c792cc44c1f"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(tfidf_train, y_train)\n",
    "# Predict on the test set\n",
    "y_pred = rf_classifier.predict(tfidf_test)\n",
    "# Calculate accuracy\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy_percentage = accuracy * 100\n",
    "print(f'Accuracy: {accuracy_percentage:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9tDjUChWK53Y",
    "outputId": "b140b3c9-aa79-4b9d-edaa-48903aa01720"
   },
   "outputs": [],
   "source": [
    "# Calculate Precision\n",
    "precision = precision_score(y_test, y_pred, pos_label='True')\n",
    "print(f'Precision: {round(precision*100, 2)}%')\n",
    "\n",
    "# Calculate Recall\n",
    "recall = recall_score(y_test, y_pred, pos_label='True')\n",
    "print(f'Recall: {round(recall*100, 2)}%')\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1 = f1_score(y_test, y_pred, pos_label='True')\n",
    "print(f'F1 Score: {round(f1*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "dWHKdVtjmkho",
    "outputId": "9ad69bec-331c-4077-a773-dba63d2b3c38"
   },
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "labels = ['Fake', 'True']\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "# Create a heatmap to visualize the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ocxNuFDnHLF",
    "outputId": "0c777f69-5f60-43db-ce10-0cb8693e6f9a"
   },
   "outputs": [],
   "source": [
    "# Initialize and train the Support Vector Machine (SVM) classifier\n",
    "svm_classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svm_classifier.fit(tfidf_train, y_train)\n",
    "# Predict on the test set\n",
    "y_pred = svm_classifier.predict(tfidf_test)\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fzWySgyqLNtZ",
    "outputId": "f350b145-6a19-4e04-8880-fe74d7362ece"
   },
   "outputs": [],
   "source": [
    "# Calculate Precision\n",
    "precision = precision_score(y_test, y_pred, pos_label='True')\n",
    "print(f'Precision: {round(precision*100, 2)}%')\n",
    "\n",
    "# Calculate Recall\n",
    "recall = recall_score(y_test, y_pred, pos_label='True')\n",
    "print(f'Recall: {round(recall*100, 2)}%')\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1 = f1_score(y_test, y_pred, pos_label='True')\n",
    "print(f'F1 Score: {round(f1*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "Lb1Q4pXanLRA",
    "outputId": "2e2be95b-d90a-4318-e0b2-f883d3d1d8d5"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the confusion matrix\n",
    "labels = ['Fake', 'True']\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "# Create a heatmap to visualize the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0po6_6tnRq5",
    "outputId": "a214e1b5-7427-4980-c3db-0507c0e9ddd0"
   },
   "outputs": [],
   "source": [
    "# Initialize and train the Naive Bayes (Multinomial) classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(tfidf_train, y_train)\n",
    "# Predict on the test set\n",
    "y_pred = nb_classifier.predict(tfidf_test)\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Irlc4jiPLO_L",
    "outputId": "df31f40e-c2e8-4982-a1e1-02c32d24b4a2"
   },
   "outputs": [],
   "source": [
    "# Calculate Precision\n",
    "precision = precision_score(y_test, y_pred, pos_label='True')\n",
    "print(f'Precision: {round(precision*100, 2)}%')\n",
    "\n",
    "# Calculate Recall\n",
    "recall = recall_score(y_test, y_pred, pos_label='True')\n",
    "print(f'Recall: {round(recall*100, 2)}%')\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1 = f1_score(y_test, y_pred, pos_label='True')\n",
    "print(f'F1 Score: {round(f1*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "jZgEofkEnWUk",
    "outputId": "e215cdd7-f8d0-4426-f802-5490124bbf62"
   },
   "outputs": [],
   "source": [
    "#Calculate the confusion matrix\n",
    "labels = ['Fake', 'True']\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "# Create a heatmap to visualize the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q605DdL7ArzF",
    "outputId": "309b8b54-d849-4821-b801-6d3b7070ec0c"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {'C': [0.1, 1, 10, 100],\n",
    "              'kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "# Create the SVM classifier\n",
    "svm_classifier = SVC(random_state=42)\n",
    "\n",
    "# Use GridSearchCV to find the best parameters\n",
    "grid_search = GridSearchCV(svm_classifier, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(tfidf_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "\n",
    "# Train the model with the best parameters\n",
    "best_svm_classifier = grid_search.best_estimator_\n",
    "best_svm_classifier.fit(tfidf_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_svm_classifier.predict(tfidf_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "# Assuming you have a new text for prediction stored in 'new_text'\n",
    "# text='new york reuters us environmental group sierra club asked environmental protection agencys inspector general investigate whether agencys head scott pruitt violated internal policies said believe carbon dioxide major contributor climate change according letter seen reuters wednesday lawyers sierra club wrote epas office inspector general tuesday asking independent watchdog check whether pruitt violated epas  scientific integrity policy told cnbc interviewer march  i would agree its primary contributor global warming see request ramps tension us environmental movement administration president donald trump called global warming hoax meant weaken us economy packed cabinet people question science climate change overwhelming majority scientists think carbon dioxide emissions burning fossil fuels major contributor global climate change triggering sea level rise droughts frequent violent storms its pretty unprecedented head epa contradicting basic scientific facts sierra club senior attorney elena saxonhouse told reuters wednesday letter sierra clubs lawyers said pruitts comments contradicted comprehensive review scientific research climate change appeared politically motivated epa website says policy meant maintain a culture scientific integrity employees requires epa officials staff ensure agencys work respects findings broader scientific community administrator pruitts comments perfectly keeping scientific integrity policy epa spokesman john konkus said email there ongoing scientific debate climate change causes effect debate encouraged administrator done discouraged sierra club attempting do spokeswoman epas inspector general said email igs office could neither confirm deny investigation requests oklahomas attorney general pruitt sued epa dozen times accepting campaign donations energy industry emails released feb  oklahoma court showed pruitt also used language provided energy company one challenges epa methane emissions regulations sierra clubs saxonhouse said group believed epas scientific integrity policy applied political appointees well career epa staff said unclear agency could enforce it shouldnt piece paper words website its intended protect public bad decisionmaking thats based real facts said'\n",
    "# text='saturday paul ryan posted photo instagram photo mass selfie large group capitol hill interns long social media commentators noticed something wrong photoin post ryan wrote think sets record number capitolhill interns single selfie speakerselfie photophoto via instagramthat huge sea white people sure interns shown photo worked hard get however problematic see people aid lawmakers even come close representing united states screenshot instagramscreenshot instagramthis matter one photo inaccurately describing racial makeup congressional aides according report released  joint center political economic studies minorities severely underrepresented capital hill one key findings report although people color make  percent us population  percent citizen votingage population represent  percent top senate staffers report also says senate offices representing states large hispanic africanamerican populations hire senior staffers color commentators quickly made connection lack diversity photo gop autopsy report concluded republican party going go extinct reach minorities try get join ranksrepublicans hate hiring mandates sure know make case clearly see photofeatured image screenshot via instagram.'\n",
    "#text='america keeps waiting word hillary indicted obama waiting right moment fbi allowed job put hillary behind bars joe biden elizabeth warren standing wings one thing know sure corrupt administration anything could happen obama seems mastered art punishing america corrupt president ever occupy white house one responsible finally putting end clinton crime syndicate know muchhillary clinton posted shared names concealed us intelligence officials unprotected email system federal records reveal clinton swapped highly classified names email account vulnerable attack breached repeatedly russialinked hacker attempts new revelations reminiscent valerie plame scandal george w bush tenure could give fbi investigators evidence need make case clinton violated espionage act mishandling national defense information gross negligence numerous names cited clinton emails redacted state department email releases classification code b cia persorg highly specialized classification means information released would violate central intelligence act the state department produced document judicial watch april  identifies different types b redactions including cia persorg defines information specifically exempted disclosure statute central intelligence act  suggests judicial watch president tom fitton told breitbart news referring indication clinton disclosed names ciaprotected intelligence sources based b redactionsthe cia justifies b redactions description b applies director statutory obligations protect disclosure intelligence sources methods well organization functions names official titles salaries numbers personnel employed agency accord national security act  cia act  respectively state department declined comment per colleague handles issue speaking content emails state department spokeswoman nicole thompson told breitbart newshere examples b redactionsnaming defense attach maltaon october   recent us ambassador malta douglas kmiec sent email cheryl mills subject line time sensitive confidential malta trip backgrounder secretary confidential kmiec wrote mills know current events life must whirlwind know ever someone could tame whirlwind would read news report secretary stop malta next week thank arranging letter accompanying clips believe help make secretary visit highly successful well received one memo kmiec revealed name top defense attach country name later classified state department three different classifications  connote foreign relations foreign activities us including confidential sources b connote information specifically authorized executive order kept secret interest national defense foreign policy b cia persorg largest part us team embassy navycoast guard ncis contingent established maritime training program afm good success defense attach new redacted beloved hardworking good effect patrolling waters ports illegible traffickers terror related figures kmiec wrotemills forwarded memo directly clinton private email account clintonemailcom note fyi background clinton replied mills cc ed huma abedin confidential information writing need enough time meet hague today right meetings copying huma reinforce desire squeeze quick trip sent memo mills douglas kmiec ambassador malta job several months kmiec big supporter president obama garnered criticism  inspector general report ignoring directives washington spending much time writing articles religion iran insights september   jackie newmyer long term strategy group cambridge massachusetts sent email directly clinton private account subject line iran insights redacted included b redaction codesecretary clintonlast week traveled israel redacted iranrelated seminar simulation exercise idf general likely become israel next chief military intelligence team separately redacted yesterday redacted iran workshop washington involving dod think tank experts despite fact meetings defense redacted personnel universal sentiment strike iran nuclear facilities would counterproductive one hand incremental measures would perceived iran indication weakness otherthe email included sensitive information including followingif iran acquires nuclear capability single americanallied countermeasure adequate something like flexible response posture cold war required necessitating range actions enhancing us deterrent presence nuclear submarines carrying ballistic missiles arabian sea bolstering regional actors defensesisraeli leaders able contain damage israeli population morale iranian bomb require careful management public statements tension building support action iranian nuclear program delivering kind reassurance necessary capability acquiredclinton replied would like discuss matter jackiejackie repliedi washington daylong meeting thursday week b redacted travel plans flexible could meet time wednesday afternoon  pm thursday time friday morning times work would happy come convenienceclinton jake sullivan set meeting jackiefor entire story breitbart news'\n",
    "text=input(\"Enter the news to be predicted: \")\n",
    "new_text_tfidf = tfidf_vectorizer.transform([text])\n",
    "\n",
    "# Make prediction using the trained SVM model\n",
    "prediction = best_svm_classifier.predict(new_text_tfidf)\n",
    "print(prediction)\n",
    "# Display the prediction\n",
    "if prediction[0] == 'True':\n",
    "    print(\"Predicted: Real News\")\n",
    "else:\n",
    "    print(\"Predicted: Fake News\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zaPfRL4KovQ_"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(best_svm_classifier,open(\"model\",\"wb\"))\n",
    "load_model=pickle.load(\"model\",\"rb\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
